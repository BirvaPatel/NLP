(tf_gpu) B:\NLP\Birvanlp-Assign-1\code>python 1111092_1dconv_reg.py
Here is the first ten row of the data set
   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  population  households  median_income  median_house_value ocean_proximity
0    -122.23     37.88                41.0        880.0           129.0       322.0       126.0         8.3252            452600.0        NEAR BAY
1    -122.22     37.86                21.0       7099.0          1106.0      2401.0      1138.0         8.3014            358500.0        NEAR BAY
2    -122.24     37.85                52.0       1467.0           190.0       496.0       177.0         7.2574            352100.0        NEAR BAY
3    -122.25     37.85                52.0       1274.0           235.0       558.0       219.0         5.6431            341300.0        NEAR BAY
4    -122.25     37.85                52.0       1627.0           280.0       565.0       259.0         3.8462            342200.0        NEAR BAY
5    -122.25     37.85                52.0        919.0           213.0       413.0       193.0         4.0368            269700.0        NEAR BAY
6    -122.25     37.84                52.0       2535.0           489.0      1094.0       514.0         3.6591            299200.0        NEAR BAY
7    -122.25     37.84                52.0       3104.0           687.0      1157.0       647.0         3.1200            241400.0        NEAR BAY
8    -122.26     37.84                42.0       2555.0           665.0      1206.0       595.0         2.0804            226700.0        NEAR BAY
9    -122.25     37.84                52.0       3549.0           707.0      1551.0       714.0         3.6912            261100.0        NEAR BAY
AxesSubplot(0.125,0.11;0.775x0.77)
Epoch1:
        Loss=140194.33670343139
        R^2Score=-2.2890146197249677
Epoch2:
        Loss=116553.7734375
        R^2Score=-1.0721996191319916
Epoch3:
        Loss=114065.32668504902
        R^2Score=-1.0414405716542536
Epoch4:
        Loss=109806.57049632353
        R^2Score=-0.7965565235904467
Epoch5:
        Loss=105947.96427696079
        R^2Score=-0.7145148491684036
Epoch6:
        Loss=103873.46807598039
        R^2Score=-0.6471575629943029
Epoch7:
        Loss=100180.43174019607
        R^2Score=-0.501145489593678
Epoch8:
        Loss=99539.81387867648
        R^2Score=-0.39739122050250425
Epoch9:
        Loss=97462.42898284314
        R^2Score=-0.3136881993153049
Epoch10:
        Loss=95400.86951593138
        R^2Score=-0.2621722119433098
Epoch11:
        Loss=92729.84169730393
        R^2Score=-0.19282316722060028
Epoch12:
        Loss=93278.0373927696
        R^2Score=-0.20111882653818353
Epoch13:
        Loss=91094.04779411765
        R^2Score=-0.10786779650202913
Epoch14:
        Loss=89803.34961703431
        R^2Score=-0.06766326722329997
Epoch15:
        Loss=89245.83299632353
        R^2Score=-0.04697095869909767
Epoch16:
        Loss=89752.95586703431
        R^2Score=-0.13283322653294558
Epoch17:
        Loss=87981.03123468137
        R^2Score=-0.05045711028276291
Epoch18:
        Loss=87602.23791360293
        R^2Score=-0.037823442544383225
Epoch19:
        Loss=87200.11418504902
        R^2Score=-0.02733034107267513
Epoch20:
        Loss=88196.06101409314
        R^2Score=-0.07476857766875315
Epoch21:
        Loss=86456.04402573529
        R^2Score=-0.004030005335909388
Epoch22:
        Loss=86765.43814338236
        R^2Score=0.001381573073617969
Epoch23:
        Loss=86004.1055300245
        R^2Score=-0.05638257529152361
Epoch24:
        Loss=86489.58694852941
        R^2Score=0.030817228294981753
Epoch25:
        Loss=83850.2825367647
        R^2Score=0.10676413255096512
Epoch26:
        Loss=84353.72029718137
        R^2Score=0.06739167047427752
Epoch27:
        Loss=84459.75755208333
        R^2Score=0.035963544437555964
Epoch28:
        Loss=83835.3474877451
        R^2Score=0.0913120659901652
Epoch29:
        Loss=83284.79750306373
        R^2Score=0.07616794816718486
Epoch30:
        Loss=84248.54797794118
        R^2Score=0.07309872380880367
Epoch31:
        Loss=83875.83909313726
        R^2Score=0.06024095382684859
Epoch32:
        Loss=84680.99368872549
        R^2Score=0.0702816263173559
Epoch33:
        Loss=83753.36162683823
        R^2Score=0.06280181790748726
Epoch34:
        Loss=82045.91078431373
        R^2Score=0.11481271967213233
Epoch35:
        Loss=82551.5116574755
        R^2Score=0.10783858233430903
Epoch36:
        Loss=82271.34325980392
        R^2Score=0.11626952988775713
Epoch37:
        Loss=82456.81870404411
        R^2Score=0.059740060211218
Epoch38:
        Loss=80798.18429840686
        R^2Score=0.14070194080809836
Epoch39:
        Loss=82356.28151041667
        R^2Score=0.08593685040870645
Epoch40:
        Loss=82604.73920036765
        R^2Score=0.09545737862212719
Epoch41:
        Loss=82400.61573223039
        R^2Score=0.11479045741631443
Epoch42:
        Loss=81410.81933210784
        R^2Score=0.11425210473555251
Epoch43:
        Loss=79788.9642310049
        R^2Score=0.14211602868731205
Epoch44:
        Loss=78991.88687193628
        R^2Score=0.17976871712683523
Epoch45:
        Loss=79669.64954044118
        R^2Score=0.18182362122260118
Epoch46:
        Loss=80621.61577818627
        R^2Score=0.16324121615477252
Epoch47:
        Loss=79789.25791973039
        R^2Score=0.18110270796865796
Epoch48:
        Loss=79264.77872242648
        R^2Score=0.19957781799385185
Epoch49:
        Loss=80159.55897671569
        R^2Score=0.18479158513910582
Epoch50:
        Loss=79508.5579810049
        R^2Score=0.16357248085238651
The model L1 loss is:77057.44419642857
The model R^2 loss is:0.20156829147669808
